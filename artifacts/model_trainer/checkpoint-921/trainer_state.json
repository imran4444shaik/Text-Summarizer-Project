{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 921,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010860711376595167,
      "grad_norm": 13.104621887207031,
      "learning_rate": 9e-07,
      "loss": 3.0679,
      "step": 10
    },
    {
      "epoch": 0.021721422753190334,
      "grad_norm": 10.080915451049805,
      "learning_rate": 1.9e-06,
      "loss": 2.9845,
      "step": 20
    },
    {
      "epoch": 0.0325821341297855,
      "grad_norm": 15.95515251159668,
      "learning_rate": 2.9e-06,
      "loss": 3.0906,
      "step": 30
    },
    {
      "epoch": 0.04344284550638067,
      "grad_norm": 25.261377334594727,
      "learning_rate": 3.9e-06,
      "loss": 3.083,
      "step": 40
    },
    {
      "epoch": 0.054303556882975834,
      "grad_norm": 20.739948272705078,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 2.7669,
      "step": 50
    },
    {
      "epoch": 0.065164268259571,
      "grad_norm": 170.51307678222656,
      "learning_rate": 5.9e-06,
      "loss": 2.8946,
      "step": 60
    },
    {
      "epoch": 0.07602497963616617,
      "grad_norm": 75.9757080078125,
      "learning_rate": 6.900000000000001e-06,
      "loss": 2.6283,
      "step": 70
    },
    {
      "epoch": 0.08688569101276133,
      "grad_norm": 9.572527885437012,
      "learning_rate": 7.9e-06,
      "loss": 2.6252,
      "step": 80
    },
    {
      "epoch": 0.0977464023893565,
      "grad_norm": 22.3438720703125,
      "learning_rate": 8.9e-06,
      "loss": 2.482,
      "step": 90
    },
    {
      "epoch": 0.10860711376595167,
      "grad_norm": 6.7607855796813965,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.3477,
      "step": 100
    },
    {
      "epoch": 0.11946782514254684,
      "grad_norm": 6.670027732849121,
      "learning_rate": 1.09e-05,
      "loss": 2.3338,
      "step": 110
    },
    {
      "epoch": 0.130328536519142,
      "grad_norm": 42.741615295410156,
      "learning_rate": 1.19e-05,
      "loss": 2.2033,
      "step": 120
    },
    {
      "epoch": 0.14118924789573717,
      "grad_norm": 9.913070678710938,
      "learning_rate": 1.29e-05,
      "loss": 2.1983,
      "step": 130
    },
    {
      "epoch": 0.15204995927233234,
      "grad_norm": 10.950576782226562,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 2.1143,
      "step": 140
    },
    {
      "epoch": 0.1629106706489275,
      "grad_norm": 5.995908737182617,
      "learning_rate": 1.49e-05,
      "loss": 2.1753,
      "step": 150
    },
    {
      "epoch": 0.17377138202552267,
      "grad_norm": 5.285055160522461,
      "learning_rate": 1.59e-05,
      "loss": 1.9906,
      "step": 160
    },
    {
      "epoch": 0.18463209340211784,
      "grad_norm": 5.616701126098633,
      "learning_rate": 1.69e-05,
      "loss": 2.0067,
      "step": 170
    },
    {
      "epoch": 0.195492804778713,
      "grad_norm": 5.748620510101318,
      "learning_rate": 1.79e-05,
      "loss": 1.9077,
      "step": 180
    },
    {
      "epoch": 0.20635351615530817,
      "grad_norm": 4.991360187530518,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 1.8898,
      "step": 190
    },
    {
      "epoch": 0.21721422753190334,
      "grad_norm": 12.657551765441895,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.9094,
      "step": 200
    },
    {
      "epoch": 0.2280749389084985,
      "grad_norm": 4.683415412902832,
      "learning_rate": 2.09e-05,
      "loss": 1.8882,
      "step": 210
    },
    {
      "epoch": 0.23893565028509367,
      "grad_norm": 5.189285755157471,
      "learning_rate": 2.19e-05,
      "loss": 1.8486,
      "step": 220
    },
    {
      "epoch": 0.24979636166168884,
      "grad_norm": 3.891071081161499,
      "learning_rate": 2.29e-05,
      "loss": 1.9461,
      "step": 230
    },
    {
      "epoch": 0.260657073038284,
      "grad_norm": 3.8426437377929688,
      "learning_rate": 2.39e-05,
      "loss": 1.7912,
      "step": 240
    },
    {
      "epoch": 0.27151778441487917,
      "grad_norm": 92.085205078125,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 1.8581,
      "step": 250
    },
    {
      "epoch": 0.28237849579147434,
      "grad_norm": 5.117231369018555,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 1.7712,
      "step": 260
    },
    {
      "epoch": 0.2932392071680695,
      "grad_norm": 5.108710289001465,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 1.7061,
      "step": 270
    },
    {
      "epoch": 0.30409991854466467,
      "grad_norm": 8.476170539855957,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 1.787,
      "step": 280
    },
    {
      "epoch": 0.31496062992125984,
      "grad_norm": 5.955401420593262,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 1.8326,
      "step": 290
    },
    {
      "epoch": 0.325821341297855,
      "grad_norm": 3.9739911556243896,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.6904,
      "step": 300
    },
    {
      "epoch": 0.33668205267445017,
      "grad_norm": 4.517691135406494,
      "learning_rate": 3.09e-05,
      "loss": 1.8396,
      "step": 310
    },
    {
      "epoch": 0.34754276405104534,
      "grad_norm": 4.36625862121582,
      "learning_rate": 3.19e-05,
      "loss": 1.8912,
      "step": 320
    },
    {
      "epoch": 0.3584034754276405,
      "grad_norm": 5.728644371032715,
      "learning_rate": 3.29e-05,
      "loss": 1.8213,
      "step": 330
    },
    {
      "epoch": 0.3692641868042357,
      "grad_norm": 8.387847900390625,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 1.7304,
      "step": 340
    },
    {
      "epoch": 0.38012489818083084,
      "grad_norm": 4.042337894439697,
      "learning_rate": 3.49e-05,
      "loss": 1.745,
      "step": 350
    },
    {
      "epoch": 0.390985609557426,
      "grad_norm": 4.141307353973389,
      "learning_rate": 3.59e-05,
      "loss": 1.6282,
      "step": 360
    },
    {
      "epoch": 0.4018463209340212,
      "grad_norm": 4.668379783630371,
      "learning_rate": 3.69e-05,
      "loss": 1.7116,
      "step": 370
    },
    {
      "epoch": 0.41270703231061634,
      "grad_norm": 3.4758853912353516,
      "learning_rate": 3.79e-05,
      "loss": 1.6923,
      "step": 380
    },
    {
      "epoch": 0.4235677436872115,
      "grad_norm": 4.212416172027588,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 1.7143,
      "step": 390
    },
    {
      "epoch": 0.4344284550638067,
      "grad_norm": 4.753016948699951,
      "learning_rate": 3.99e-05,
      "loss": 1.7029,
      "step": 400
    },
    {
      "epoch": 0.44528916644040184,
      "grad_norm": 20.230154037475586,
      "learning_rate": 4.09e-05,
      "loss": 1.7108,
      "step": 410
    },
    {
      "epoch": 0.456149877816997,
      "grad_norm": 12.499466896057129,
      "learning_rate": 4.19e-05,
      "loss": 1.6301,
      "step": 420
    },
    {
      "epoch": 0.4670105891935922,
      "grad_norm": 4.2044358253479,
      "learning_rate": 4.29e-05,
      "loss": 1.7655,
      "step": 430
    },
    {
      "epoch": 0.47787130057018734,
      "grad_norm": 5.094773769378662,
      "learning_rate": 4.39e-05,
      "loss": 1.6936,
      "step": 440
    },
    {
      "epoch": 0.4887320119467825,
      "grad_norm": 5.814359664916992,
      "learning_rate": 4.49e-05,
      "loss": 1.659,
      "step": 450
    },
    {
      "epoch": 0.4995927233233777,
      "grad_norm": 6.029466152191162,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 1.7216,
      "step": 460
    },
    {
      "epoch": 0.5104534346999728,
      "grad_norm": 16.913585662841797,
      "learning_rate": 4.69e-05,
      "loss": 1.6967,
      "step": 470
    },
    {
      "epoch": 0.521314146076568,
      "grad_norm": 4.148979187011719,
      "learning_rate": 4.79e-05,
      "loss": 1.6178,
      "step": 480
    },
    {
      "epoch": 0.5321748574531632,
      "grad_norm": 11.331104278564453,
      "learning_rate": 4.89e-05,
      "loss": 1.6469,
      "step": 490
    },
    {
      "epoch": 0.5430355688297583,
      "grad_norm": 5.3301191329956055,
      "learning_rate": 4.99e-05,
      "loss": 1.6929,
      "step": 500
    },
    {
      "epoch": 0.5430355688297583,
      "eval_loss": 1.4855597019195557,
      "eval_runtime": 429.4028,
      "eval_samples_per_second": 1.905,
      "eval_steps_per_second": 1.905,
      "step": 500
    },
    {
      "epoch": 0.5538962802063535,
      "grad_norm": 4.335214138031006,
      "learning_rate": 4.89311163895487e-05,
      "loss": 1.6779,
      "step": 510
    },
    {
      "epoch": 0.5647569915829487,
      "grad_norm": 3.430973768234253,
      "learning_rate": 4.7743467933491685e-05,
      "loss": 1.6239,
      "step": 520
    },
    {
      "epoch": 0.5756177029595438,
      "grad_norm": 4.020521640777588,
      "learning_rate": 4.655581947743468e-05,
      "loss": 1.6897,
      "step": 530
    },
    {
      "epoch": 0.586478414336139,
      "grad_norm": 3.5420749187469482,
      "learning_rate": 4.536817102137767e-05,
      "loss": 1.584,
      "step": 540
    },
    {
      "epoch": 0.5973391257127342,
      "grad_norm": 4.10534143447876,
      "learning_rate": 4.418052256532067e-05,
      "loss": 1.6623,
      "step": 550
    },
    {
      "epoch": 0.6081998370893293,
      "grad_norm": 4.192720413208008,
      "learning_rate": 4.299287410926366e-05,
      "loss": 1.6904,
      "step": 560
    },
    {
      "epoch": 0.6190605484659245,
      "grad_norm": 3.3813350200653076,
      "learning_rate": 4.1805225653206655e-05,
      "loss": 1.7171,
      "step": 570
    },
    {
      "epoch": 0.6299212598425197,
      "grad_norm": 4.78154182434082,
      "learning_rate": 4.061757719714965e-05,
      "loss": 1.6286,
      "step": 580
    },
    {
      "epoch": 0.6407819712191148,
      "grad_norm": 3.885016679763794,
      "learning_rate": 3.9429928741092636e-05,
      "loss": 1.5939,
      "step": 590
    },
    {
      "epoch": 0.65164268259571,
      "grad_norm": 3.1963491439819336,
      "learning_rate": 3.824228028503563e-05,
      "loss": 1.6821,
      "step": 600
    },
    {
      "epoch": 0.6625033939723052,
      "grad_norm": 3.7183852195739746,
      "learning_rate": 3.7054631828978624e-05,
      "loss": 1.5753,
      "step": 610
    },
    {
      "epoch": 0.6733641053489003,
      "grad_norm": 5.132885932922363,
      "learning_rate": 3.586698337292162e-05,
      "loss": 1.6308,
      "step": 620
    },
    {
      "epoch": 0.6842248167254955,
      "grad_norm": 4.6181416511535645,
      "learning_rate": 3.467933491686461e-05,
      "loss": 1.6603,
      "step": 630
    },
    {
      "epoch": 0.6950855281020907,
      "grad_norm": 3.701625108718872,
      "learning_rate": 3.3491686460807606e-05,
      "loss": 1.642,
      "step": 640
    },
    {
      "epoch": 0.7059462394786858,
      "grad_norm": 3.989123582839966,
      "learning_rate": 3.23040380047506e-05,
      "loss": 1.5147,
      "step": 650
    },
    {
      "epoch": 0.716806950855281,
      "grad_norm": 6.160187721252441,
      "learning_rate": 3.111638954869359e-05,
      "loss": 1.5672,
      "step": 660
    },
    {
      "epoch": 0.7276676622318762,
      "grad_norm": 5.400448799133301,
      "learning_rate": 2.992874109263658e-05,
      "loss": 1.6114,
      "step": 670
    },
    {
      "epoch": 0.7385283736084713,
      "grad_norm": 3.8475422859191895,
      "learning_rate": 2.8741092636579575e-05,
      "loss": 1.5857,
      "step": 680
    },
    {
      "epoch": 0.7493890849850665,
      "grad_norm": 6.0764570236206055,
      "learning_rate": 2.7553444180522565e-05,
      "loss": 1.5578,
      "step": 690
    },
    {
      "epoch": 0.7602497963616617,
      "grad_norm": 3.8739607334136963,
      "learning_rate": 2.636579572446556e-05,
      "loss": 1.634,
      "step": 700
    },
    {
      "epoch": 0.7711105077382568,
      "grad_norm": 4.61893892288208,
      "learning_rate": 2.5178147268408553e-05,
      "loss": 1.6005,
      "step": 710
    },
    {
      "epoch": 0.781971219114852,
      "grad_norm": 6.254213809967041,
      "learning_rate": 2.3990498812351544e-05,
      "loss": 1.5892,
      "step": 720
    },
    {
      "epoch": 0.7928319304914472,
      "grad_norm": 5.463415145874023,
      "learning_rate": 2.2802850356294538e-05,
      "loss": 1.5421,
      "step": 730
    },
    {
      "epoch": 0.8036926418680423,
      "grad_norm": 3.312006711959839,
      "learning_rate": 2.161520190023753e-05,
      "loss": 1.643,
      "step": 740
    },
    {
      "epoch": 0.8145533532446375,
      "grad_norm": 19.97408103942871,
      "learning_rate": 2.0427553444180522e-05,
      "loss": 1.5963,
      "step": 750
    },
    {
      "epoch": 0.8254140646212327,
      "grad_norm": 4.09841775894165,
      "learning_rate": 1.9239904988123516e-05,
      "loss": 1.6073,
      "step": 760
    },
    {
      "epoch": 0.8362747759978278,
      "grad_norm": 3.819321870803833,
      "learning_rate": 1.8052256532066507e-05,
      "loss": 1.5674,
      "step": 770
    },
    {
      "epoch": 0.847135487374423,
      "grad_norm": 5.191666603088379,
      "learning_rate": 1.6864608076009504e-05,
      "loss": 1.5611,
      "step": 780
    },
    {
      "epoch": 0.8579961987510182,
      "grad_norm": 5.394824028015137,
      "learning_rate": 1.5676959619952495e-05,
      "loss": 1.5537,
      "step": 790
    },
    {
      "epoch": 0.8688569101276133,
      "grad_norm": 4.065023422241211,
      "learning_rate": 1.4489311163895489e-05,
      "loss": 1.6684,
      "step": 800
    },
    {
      "epoch": 0.8797176215042085,
      "grad_norm": 4.256457328796387,
      "learning_rate": 1.3301662707838481e-05,
      "loss": 1.553,
      "step": 810
    },
    {
      "epoch": 0.8905783328808037,
      "grad_norm": 3.217038154602051,
      "learning_rate": 1.2114014251781473e-05,
      "loss": 1.6217,
      "step": 820
    },
    {
      "epoch": 0.9014390442573988,
      "grad_norm": 3.559748888015747,
      "learning_rate": 1.0926365795724467e-05,
      "loss": 1.653,
      "step": 830
    },
    {
      "epoch": 0.912299755633994,
      "grad_norm": 5.473207473754883,
      "learning_rate": 9.73871733966746e-06,
      "loss": 1.5149,
      "step": 840
    },
    {
      "epoch": 0.9231604670105892,
      "grad_norm": 4.6073431968688965,
      "learning_rate": 8.551068883610452e-06,
      "loss": 1.554,
      "step": 850
    },
    {
      "epoch": 0.9340211783871843,
      "grad_norm": 3.693303108215332,
      "learning_rate": 7.363420427553444e-06,
      "loss": 1.5631,
      "step": 860
    },
    {
      "epoch": 0.9448818897637795,
      "grad_norm": 3.6681175231933594,
      "learning_rate": 6.175771971496437e-06,
      "loss": 1.5529,
      "step": 870
    },
    {
      "epoch": 0.9557426011403747,
      "grad_norm": 5.654201507568359,
      "learning_rate": 4.98812351543943e-06,
      "loss": 1.532,
      "step": 880
    },
    {
      "epoch": 0.9666033125169698,
      "grad_norm": 3.1936471462249756,
      "learning_rate": 3.8004750593824232e-06,
      "loss": 1.5231,
      "step": 890
    },
    {
      "epoch": 0.977464023893565,
      "grad_norm": 3.6443941593170166,
      "learning_rate": 2.612826603325416e-06,
      "loss": 1.5748,
      "step": 900
    },
    {
      "epoch": 0.9883247352701602,
      "grad_norm": 6.11838436126709,
      "learning_rate": 1.4251781472684086e-06,
      "loss": 1.5389,
      "step": 910
    },
    {
      "epoch": 0.9991854466467553,
      "grad_norm": 4.817695617675781,
      "learning_rate": 2.3752969121140145e-07,
      "loss": 1.5847,
      "step": 920
    }
  ],
  "logging_steps": 10,
  "max_steps": 921,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5531718781673472.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
